{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a8e88d-ff00-4d61-92e2-2aede31355f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a142fb-15f8-4738-80b7-1f93d2138f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Titanic-Dataset.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c8641-7829-45e8-ac12-de8d529f3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d9a66-9cd1-4432-b830-91ec61abf670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b66f781-1baf-4e82-80e6-3bee128321ee",
   "metadata": {},
   "source": [
    "1. Since age has about 177 null values and Embarked has about 2 null values lets drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55149a85-87fa-41e7-99c6-1e29318ddec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Age', 'Embarked'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f8bbd-9370-4c64-890a-baac790d22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.Age.isna().sum())\n",
    "print(df.Embarked.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce59863-aebc-4706-b570-8af61bb07a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8e6cc6-aebc-4def-954d-7f51841ca235",
   "metadata": {},
   "source": [
    "## Encoding:\n",
    "1. Label encoding: Sex\n",
    "2. Hot encoding: Embarked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c7b89-b223-4cdf-92b1-55e457cc90fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df.Sex = le.fit_transform(df.Sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae718d4-e0a1-4627-839c-991fc582a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d118a0f-c7dc-4e52-a39a-e57aa9681df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'] = df['Embarked'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a312603-61a8-4b0a-b96a-93c3dbda7ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dummy = pd.get_dummies(df.Embarked)\n",
    "emb_dummy = emb_dummy.astype(int)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "emb_dummy.reset_index(drop=True, inplace=True)\n",
    "df = pd.concat([df, emb_dummy], axis=1)  \n",
    "df.drop(columns=['Embarked'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daae26c-38c9-4ade-9235-ac68a22e3385",
   "metadata": {},
   "source": [
    "2. Now the feature Cabin has about 687 null values, which is a significant number so instead of dropping the values, we will first check how significantly is it correlated to the target and on that we will either replace it with mean or median.\n",
    "\n",
    "3. For Correlation we will use heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "d8ef337c-f2ef-49c3-bec0-367943639a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "r_df = df.drop(columns = ['Name', 'Ticket', 'Cabin'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4ecfb-62a8-4c0a-8f79-f54225d1ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "r = r_df.corr()\n",
    "sns.heatmap(r, annot = True, cmap = plt.cm.CMRmap_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc8afed-2316-4e8c-9126-24ff57fc3d17",
   "metadata": {},
   "source": [
    "From the above analysis we get:\n",
    "1. Survival(Target) is highly correlated to: Pclass, Sex.\n",
    "2. Pclass and Fare are highy correlated so we can use either of them, but since our dataset is small well consider both.\n",
    "3. Sibsp and Parch are significantly correlated, so we can use either of them, but since our dataset is small well consider both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733957db-fea5-49b9-8687-fb11811bd487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0329f85b-f129-4fa7-be27-0d562fa2e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df.drop(['Survived','PassengerId', 'Name', 'Age', 'Ticket', 'Cabin'], axis = 1)\n",
    "y = df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b54763-fb86-4945-a6b6-87fee71c82a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976595da-67d0-474f-8a83-b9e179d5d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc383ea1-f8e5-431c-97a6-dcc7214db4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e91d80-cb2e-4f60-84c4-7165cbf0236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef9e7a-74df-43dc-a4f0-ac4c89874f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b7c6a0-6a8c-48d3-9ba7-ca08d13e62da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=7, )\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8537ab8c-6d71-4686-aaab-bfc33352eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047afb6e-7065-45fd-ba10-99e1135b2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ae52c-a598-46d8-be1f-bff1345bc816",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "correct_predictions = (results_df['Actual'] == results_df['Predicted']).sum()\n",
    "wrong_predictions = (results_df['Actual'] != results_df['Predicted']).sum()\n",
    "print(\"Total Values\", len(y_test))\n",
    "print(\"Total number of correct predictions:\", correct_predictions)\n",
    "print(\"Total number of wrong predictions:\", wrong_predictions)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a22d376-5d7b-4c94-b034-02ceefa77f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = (results_df['Actual'] == results_df['Predicted']).sum()\n",
    "wrong_predictions = (results_df['Actual'] != results_df['Predicted']).sum()\n",
    "print(\"Total Values:\", len(y_test))\n",
    "print(\"Total number of correct predictions:\", correct_predictions)\n",
    "print(\"Total number of wrong predictions:\", wrong_predictions)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e5f25-0088-440b-bcb3-c1c1bcf8d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'diabetesModel.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a4e61-17a5-4728-b3ae-fe98b3507348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
